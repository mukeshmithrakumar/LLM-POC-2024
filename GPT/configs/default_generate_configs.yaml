init_from: "resume" # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')
out_dir: "out" # ignored if init_from is not 'resume'
start: "\n" # or "<|endoftext|>" or etc. Can also specify a file, use as: "FILE:prompt.txt"
num_samples: 10 # number of samples to draw
max_new_tokens: 500 # number of tokens generated in each sample
temperature: 0.8 # 1.0 : no change, < 1.0 : less random, > 1.0 : more random, in predictions
top_k: 200 # retain only the top_k most likely tokens, clamp others to have 0 probability
seed: 1337
device: "cuda" # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.
compile: False # use PyTorch 2.0 to compile the model to be faster
